{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application Steps (SQL Server Data Profile example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Initalize application by loading common libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application run path set as: /home/vwon23/repos/apps/streamlit-data-profiler/app_run\n",
      "Current Time in PST: 2024-06-17 10:42:11\n",
      "06/17/2024 10:42:11 AM - utilities.common_functions - INFO - logs being written to /home/vwon23/repos/apps/streamlit-data-profiler/logs/example_mssql_connection_2024-06-17.log\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "import dtale\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "import sqlalchemy as sal\n",
    "\n",
    "## Find path of the script then find the path app_run and add it to system path ##\n",
    "# path_script = os.path.abspath(__file__)\n",
    "# path_app_run = os.path.dirname(os.path.dirname(path_script))\n",
    "path_script_dir = os.getcwd()\n",
    "path_app_run = os.path.dirname(path_script_dir)\n",
    "\n",
    "sys.path.append(path_app_run)\n",
    "\n",
    "## use common functions to initalize global variable and set logger ##\n",
    "import utilities.common_functions as cf\n",
    "import queries.sf_queries as sfq\n",
    "\n",
    "loggername = 'example_mssql_connection'\n",
    "logger = cf.initialize(path_app_run, loggername)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mssql+pyodbc://vwon2:Code23@G15_5520/AdventureWorksLT2022?driver=ODBC+Driver+17+for+SQL+Server\n",
      "06/17/2024 10:44:54 AM - example_mssql_connection - ERROR - Error connecting to Microsoft SQL Server G15_5520 and database AdventureWorksLT2022\n",
      "libodbc.so.2: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "\n",
    "server = cf.gvar.mssql_server\n",
    "database = cf.gvar.mssql_database\n",
    "username=cf.gvar.mssql_username\n",
    "password=cf.gvar.mssql_password\n",
    "\n",
    "mssql_engine_url_template = {\n",
    "    'windows_auth': {\n",
    "        'url_format': 'mssql+pyodbc://{server}/{database}?trusted_connection=yes&driver={driver}',\n",
    "        'driver': 'SQL Server Native Client 11.0'\n",
    "        },\n",
    "    'sql_auth': {\n",
    "        'url_format': 'mssql+pyodbc://{username}:{password}@{server}/{database}?driver={driver}',\n",
    "        'driver': 'ODBC+Driver+17+for+SQL+Server'\n",
    "        }\n",
    "    }\n",
    "\n",
    "mssql_engine_url = mssql_engine_url_template['sql_auth']['url_format'].format(\n",
    "    username=username,\n",
    "    password=password,\n",
    "    server=server, database=database,\n",
    "    driver=mssql_engine_url_template['sql_auth']['driver'])\n",
    "\n",
    "print(mssql_engine_url)\n",
    "\n",
    "\n",
    "try:\n",
    "    engine = sal.create_engine(mssql_engine_url)\n",
    "    logger.info(f'Successfully connected to Microsoft SQL Server {server} and database {database}')\n",
    "except Exception as e:\n",
    "    logger.error(f'Error connecting to Microsoft SQL Server {server} and database {database}\\n' + f'{e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/17/2024 10:42:16 AM - example_mssql_connection - INFO - Connecting to Microsoft SQL Server G15_5520 and database AdventureWorksLT2022\n",
      "06/17/2024 10:42:16 AM - example_mssql_connection - ERROR - Error connecting to Microsoft SQL Server G15_5520 and database AdventureWorksLT2022\n",
      "libodbc.so.2: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "\n",
    "server = cf.gvar.mssql_server\n",
    "database = cf.gvar.mssql_database\n",
    "\n",
    "def sal_create_enginem_ms_sql(server, database, windows_auth=True):\n",
    "    mssql_engine_url_template = {\n",
    "        'windows_auth': {\n",
    "            'url_format': 'mssql+pyodbc://{server}/{database}?trusted_connection=yes&driver={driver}',\n",
    "            'driver': 'SQL Server Native Client 11.0'\n",
    "            },\n",
    "        'sql_auth': {\n",
    "            'url_format': 'mssql+pyodbc://{username}:{password}@{server}/{database}?driver={driver}',\n",
    "            'driver': 'ODBC+Driver+17+for+SQL+Server'\n",
    "            }\n",
    "        }\n",
    "\n",
    "    if windows_auth:\n",
    "        mssql_engine_url = mssql_engine_url_template['windows_auth']['url_format'].format(\n",
    "            server=server,\n",
    "            database=database,\n",
    "            driver=mssql_engine_url_template['windows_auth']['driver'])\n",
    "    else:\n",
    "        mssql_engine_url = mssql_engine_url_template['sql_auth']['url_format'].format(\n",
    "            username=cf.gvar.mssql_username,\n",
    "            password=cf.gvar.mssql_password,\n",
    "            server=server, database=database,\n",
    "            driver=mssql_engine_url_template['sql_auth']['driver'])\n",
    "\n",
    "\n",
    "    logger.info(f'Connecting to Microsoft SQL Server {server} and database {database}')\n",
    "    try:\n",
    "        engine = sal.create_engine(mssql_engine_url)\n",
    "        logger.info(f'Successfully connected to Microsoft SQL Server {server} and database {database}')\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        logger.error(f'Error connecting to Microsoft SQL Server {server} and database {database}\\n' + f'{e}')\n",
    "\n",
    "engine = sal_create_enginem_ms_sql(server=server, database=database, windows_auth=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "select  ordinal_position,\n",
    "        column_name\n",
    "from AdventureWorksLT2022.information_schema.columns\n",
    "where table_schema = 'SalesLT'\n",
    "and table_name = 'Customer';\n",
    "'''\n",
    "\n",
    "df = cf.sal_exec_query_return_df(engine, sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Query information schema data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions used to get list of databases, schemas and tables from snowflake ##\n",
    "def list_sf_databases(sf_role, sf_wh):\n",
    "    cf.gvar.sf_conn.execute_string(sfq.use_role_wh.format(sf_role=sf_role, sf_wh=sf_wh), return_cursors=False)\n",
    "    df = cf.sf_exec_query_return_df(sfq.show_databases)\n",
    "    list_dbs = df['name'].tolist()\n",
    "    list_dbs.sort()\n",
    "    return list_dbs\n",
    "\n",
    "def list_sf_schemas(db):\n",
    "    df = cf.sf_exec_query_return_df(sfq.list_schemas.format(db_name=db))\n",
    "    list_schemas = df['TABLE_SCHEMA'].tolist()\n",
    "    list_schemas.sort()\n",
    "    return list_schemas\n",
    "\n",
    "def list_sf_tables(db, schema):\n",
    "    df = cf.sf_exec_query_return_df(sfq.list_tables.format(db_name=db, schema=schema))\n",
    "    list_tables = df['TABLE_NAME'].tolist()\n",
    "    list_tables.sort()\n",
    "    return list_tables\n",
    "\n",
    "def list_sf_columns(db, schema, table):\n",
    "    df = cf.sf_exec_query_return_df(sfq.get_columns.format(db_name=db, schema=schema, table=table))\n",
    "    df.sort_values(by='ORDINAL_POSITION', inplace=True)\n",
    "    list_columns = df['COLUMN_NAME'].tolist()\n",
    "    return list_columns\n",
    "\n",
    "list_dbs = list_sf_databases(sf_role, sf_wh)\n",
    "db = list_dbs[0]\n",
    "\n",
    "list_schemas = list_sf_schemas(db)\n",
    "schema = list_schemas[0]\n",
    "\n",
    "list_tables = list_sf_tables(db, schema)\n",
    "table = list_tables[0]\n",
    "\n",
    "list_columns = list_sf_columns(db, schema, table)\n",
    "str_columns = ', '.join(list_columns)\n",
    "\n",
    "print(\n",
    "    'database:    ' + db +\n",
    "    '\\nschema:      ' + schema +\n",
    "    '\\ntable:       ' + table +\n",
    "    '\\ncolumns:     ' + str_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Generate SQL statement to send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_base(db, schema, table, str_columns):\n",
    "    sql = f'select  {str_columns}\\nfrom  {db}.{schema}.{table}'\n",
    "    return sql\n",
    "\n",
    "sql = generate_sql_base(db, schema, table, str_columns)\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Send SQL to query data and store result into pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_sf_query_df(sql):\n",
    "    df = cf.sf_exec_query_return_df(sql)\n",
    "    return df\n",
    "\n",
    "df = return_sf_query_df(sql)\n",
    "\n",
    "print('\\nDisplaying First 10 rows of queried result:')\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Profile DataFrame using dtale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting D-Tale')\n",
    "d = dtale.show(df, host='localhost')\n",
    "d.open_browser()\n",
    "dtale_running = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Profile DataFrame using ydata-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dtale_running:\n",
    "    print('D-Tale is running. Shutting down..')\n",
    "    d.kill()\n",
    "    dtale_running = False\n",
    "\n",
    "def profile_data_ydata(df):\n",
    "    pr = ProfileReport(df,\n",
    "                    title=db + '.' + schema + '.' + table,\n",
    "                    minimal=True,\n",
    "                    explorative=False,\n",
    "                    correlations=None,\n",
    "                    infer_dtypes=False,\n",
    "                    vars={\n",
    "                        \"num\": {\"low_categorical_threshold\": 0},\n",
    "                        \"cat\": {\n",
    "                            \"length\": True,\n",
    "                            \"characters\": False,\n",
    "                            \"words\": False,\n",
    "                            \"n_obs\": 10,\n",
    "                        },\n",
    "                    },\n",
    "                    orange_mode=True)\n",
    "    pr.to_notebook_iframe()\n",
    "\n",
    "profile_data_ydata(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
